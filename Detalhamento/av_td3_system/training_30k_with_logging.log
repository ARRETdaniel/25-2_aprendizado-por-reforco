WARNING:root:Could not import GlobalRoutePlanner from agents.navigation. Ensure CARLA Python API is installed and PythonAPI/carla/agents is in PYTHONPATH.

======================================================================
TD3 TRAINING PIPELINE - AUTONOMOUS VEHICLE NAVIGATION
======================================================================

[CONFIG] Loading configurations...
[CONFIG] CARLA config: config/carla_config.yaml
[CONFIG] Agent config: config/td3_config.yaml
[CONFIG] Scenario: 0 (0=20, 1=50, 2=100 NPCs)
[CONFIG] NPC count set to: 20

[ENVIRONMENT] Initializing CARLA environment...
WARNING:src.environment.carla_env:Failed to initialize DynamicRouteManager: GlobalRoutePlanner not available. Ensure CARLA agents package is installed.
Falling back to legacy waypoint manager
[ENVIRONMENT] State space: Dict('image': Box(0.0, 1.0, (4, 84, 84), float32), 'vector': Box(-inf, inf, (23,), float32))
[ENVIRONMENT] Action space: Box(-1.0, 1.0, (2,), float32)

[AGENT] Initializing TD3 agent...
[AGENT] Device explicitly set to: cpu
[AGENT] Running on CPU to reserve GPU memory for CARLA simulator
TD3Agent initialized on device: cpu (manually specified)
TD3Agent initialized with:
  State dim: 535, Action dim: 2
  Actor hidden size: [256, 256]
  Critic hidden size: [256, 256]
  Discount γ: 0.99, Tau τ: 0.005
  Policy freq: 2, Policy noise: 0.2
  Exploration noise: 0.1
  Buffer size: 1000000, Batch size: 256
[AGENT] Initializing NatureCNN feature extractor...
[AGENT] CNN extractor initialized on cpu
[AGENT] CNN architecture: 4×84×84 → Conv layers → 512 features
[LOGGING] TensorBoard logs: data/logs/TD3_scenario_0_npcs_20_20251026-013222

[INIT] Training pipeline ready!
[INIT] Max timesteps: 30,000
[INIT] Seed: 42
======================================================================

[TRAINING] Starting training loop...
[TRAINING] Initializing CARLA environment (spawning actors)...
[TRAINING] This may take 1-5 minutes on first reset. Please be patient...
[TRAINING] Connecting to CARLA server...
WARNING:src.environment.carla_env:No scenarios found in config, using default NPC count: 50
[TRAINING] Environment initialized successfully in 4.3 seconds!
[TRAINING] Actors spawned, sensors ready
[TRAINING] Beginning training from timestep 1 to 30,000

[TRAINING PHASES]
  Phase 1 (Steps 1-10,000): EXPLORATION (random actions, filling replay buffer)
  Phase 2 (Steps 10,001-30,000): LEARNING (policy updates)
  Evaluation every 5,000 steps
  Checkpoints every 10,000 steps

[PROGRESS] Training starting now - logging every 100 steps...

[EXPLORATION] Processing step    100/30,000...
[EXPLORATION] Step    100/30,000 | Episode    0 | Ep Step  100 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    100/1000000
[EXPLORATION] Processing step    200/30,000...
[EXPLORATION] Step    200/30,000 | Episode    0 | Ep Step  200 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    200/1000000
[EXPLORATION] Processing step    300/30,000...
[EXPLORATION] Step    300/30,000 | Episode    0 | Ep Step  300 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    300/1000000
[EXPLORATION] Processing step    400/30,000...
[EXPLORATION] Step    400/30,000 | Episode    0 | Ep Step  400 | Reward=  -1.00 | Speed=  0.1 km/h | Buffer=    400/1000000
[EXPLORATION] Processing step    500/30,000...
[EXPLORATION] Step    500/30,000 | Episode    0 | Ep Step  500 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    500/1000000
[EXPLORATION] Processing step    600/30,000...
[EXPLORATION] Step    600/30,000 | Episode    0 | Ep Step  600 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    600/1000000
[EXPLORATION] Processing step    700/30,000...
[EXPLORATION] Step    700/30,000 | Episode    0 | Ep Step  700 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    700/1000000
[EXPLORATION] Processing step    800/30,000...
[EXPLORATION] Step    800/30,000 | Episode    0 | Ep Step  800 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    800/1000000
[EXPLORATION] Processing step    900/30,000...
[EXPLORATION] Step    900/30,000 | Episode    0 | Ep Step  900 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=    900/1000000
[EXPLORATION] Processing step   1000/30,000...
[EXPLORATION] Step   1000/30,000 | Episode    0 | Ep Step 1000 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1000/1000000
[EXPLORATION] Processing step   1100/30,000...
[EXPLORATION] Step   1100/30,000 | Episode    0 | Ep Step 1100 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1100/1000000
[EXPLORATION] Processing step   1200/30,000...
[EXPLORATION] Step   1200/30,000 | Episode    0 | Ep Step 1200 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1200/1000000
[EXPLORATION] Processing step   1300/30,000...
[EXPLORATION] Step   1300/30,000 | Episode    0 | Ep Step 1300 | Reward=  -1.00 | Speed=  0.4 km/h | Buffer=   1300/1000000
[EXPLORATION] Processing step   1400/30,000...
[EXPLORATION] Step   1400/30,000 | Episode    0 | Ep Step 1400 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1400/1000000
[EXPLORATION] Processing step   1500/30,000...
[EXPLORATION] Step   1500/30,000 | Episode    0 | Ep Step 1500 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1500/1000000
[EXPLORATION] Processing step   1600/30,000...
[EXPLORATION] Step   1600/30,000 | Episode    0 | Ep Step 1600 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1600/1000000
[EXPLORATION] Processing step   1700/30,000...
[EXPLORATION] Step   1700/30,000 | Episode    0 | Ep Step 1700 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1700/1000000
[EXPLORATION] Processing step   1800/30,000...
[EXPLORATION] Step   1800/30,000 | Episode    0 | Ep Step 1800 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1800/1000000
[EXPLORATION] Processing step   1900/30,000...
[EXPLORATION] Step   1900/30,000 | Episode    0 | Ep Step 1900 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   1900/1000000
[EXPLORATION] Processing step   2000/30,000...
[EXPLORATION] Step   2000/30,000 | Episode    0 | Ep Step 2000 | Reward=  -1.00 | Speed=  0.2 km/h | Buffer=   2000/1000000
[EXPLORATION] Processing step   2100/30,000...
[EXPLORATION] Step   2100/30,000 | Episode    0 | Ep Step 2100 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   2100/1000000
[EXPLORATION] Processing step   2200/30,000...
[EXPLORATION] Step   2200/30,000 | Episode    0 | Ep Step 2200 | Reward=  -0.99 | Speed=  1.0 km/h | Buffer=   2200/1000000
[EXPLORATION] Processing step   2300/30,000...
[EXPLORATION] Step   2300/30,000 | Episode    0 | Ep Step 2300 | Reward=  -1.00 | Speed=  0.4 km/h | Buffer=   2300/1000000
[EXPLORATION] Processing step   2400/30,000...
[EXPLORATION] Step   2400/30,000 | Episode    0 | Ep Step 2400 | Reward=  -1.00 | Speed=  0.3 km/h | Buffer=   2400/1000000
[EXPLORATION] Processing step   2500/30,000...
[EXPLORATION] Step   2500/30,000 | Episode    0 | Ep Step 2500 | Reward=  -1.00 | Speed=  0.0 km/h | Buffer=   2500/1000000
